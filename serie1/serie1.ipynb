{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "_Author: Maxime Welcklen_\\\r\n",
    "_Objective: Understand and vizualise the stock data_\r\n",
    "\r\n",
    "# Serie1  notebook\r\n",
    "This notebook will walk you through my serie1 : Discovery and first steps of the CAC40 dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start with importing the CSV file as a dataframe !"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\r\n",
    "import os\r\n",
    "\r\n",
    "\r\n",
    "DATA_FILEPATH = \"data/CAC40.csv\"\r\n",
    "\r\n",
    "def fetch_data():\r\n",
    "    \"\"\"Import the data from csv to pd dataframe\"\"\"\r\n",
    "    relaviteFilepath = os.path.join(os.path.abspath(''), DATA_FILEPATH)\r\n",
    "    return pd.read_csv(relaviteFilepath)\r\n",
    "\r\n",
    "# df stands for dataframe. This is the object that we will manipulate throughouht the notebook\r\n",
    "cac40df = fetch_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's print the DF to see if the import went well"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(cac40df)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-03-01</td>\n",
       "      <td>1836.000000</td>\n",
       "      <td>1838.000000</td>\n",
       "      <td>1827.000000</td>\n",
       "      <td>1832.000000</td>\n",
       "      <td>1832.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-03-02</td>\n",
       "      <td>1831.000000</td>\n",
       "      <td>1860.000000</td>\n",
       "      <td>1831.000000</td>\n",
       "      <td>1860.000000</td>\n",
       "      <td>1860.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-03-05</td>\n",
       "      <td>1866.000000</td>\n",
       "      <td>1874.000000</td>\n",
       "      <td>1862.000000</td>\n",
       "      <td>1874.000000</td>\n",
       "      <td>1874.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990-03-06</td>\n",
       "      <td>1869.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>1866.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990-03-07</td>\n",
       "      <td>1874.000000</td>\n",
       "      <td>1881.000000</td>\n",
       "      <td>1874.000000</td>\n",
       "      <td>1880.000000</td>\n",
       "      <td>1880.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>2021-09-15</td>\n",
       "      <td>6654.830078</td>\n",
       "      <td>6659.270020</td>\n",
       "      <td>6577.020020</td>\n",
       "      <td>6583.620117</td>\n",
       "      <td>6583.620117</td>\n",
       "      <td>81904200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>2021-09-16</td>\n",
       "      <td>6613.709961</td>\n",
       "      <td>6663.410156</td>\n",
       "      <td>6612.160156</td>\n",
       "      <td>6622.589844</td>\n",
       "      <td>6622.589844</td>\n",
       "      <td>79574500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>6679.450195</td>\n",
       "      <td>6697.080078</td>\n",
       "      <td>6551.620117</td>\n",
       "      <td>6570.189941</td>\n",
       "      <td>6570.189941</td>\n",
       "      <td>214025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8002</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>6450.390137</td>\n",
       "      <td>6471.089844</td>\n",
       "      <td>6389.620117</td>\n",
       "      <td>6455.810059</td>\n",
       "      <td>6455.810059</td>\n",
       "      <td>120069400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8003</th>\n",
       "      <td>2021-09-21</td>\n",
       "      <td>6513.750000</td>\n",
       "      <td>6570.129883</td>\n",
       "      <td>6513.750000</td>\n",
       "      <td>6552.729980</td>\n",
       "      <td>6552.729980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8004 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date         Open         High          Low        Close  \\\n",
       "0     1990-03-01  1836.000000  1838.000000  1827.000000  1832.000000   \n",
       "1     1990-03-02  1831.000000  1860.000000  1831.000000  1860.000000   \n",
       "2     1990-03-05  1866.000000  1874.000000  1862.000000  1874.000000   \n",
       "3     1990-03-06  1869.000000  1875.000000  1866.000000  1872.000000   \n",
       "4     1990-03-07  1874.000000  1881.000000  1874.000000  1880.000000   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "7999  2021-09-15  6654.830078  6659.270020  6577.020020  6583.620117   \n",
       "8000  2021-09-16  6613.709961  6663.410156  6612.160156  6622.589844   \n",
       "8001  2021-09-17  6679.450195  6697.080078  6551.620117  6570.189941   \n",
       "8002  2021-09-20  6450.390137  6471.089844  6389.620117  6455.810059   \n",
       "8003  2021-09-21  6513.750000  6570.129883  6513.750000  6552.729980   \n",
       "\n",
       "        Adj Close     Volume  \n",
       "0     1832.000000          0  \n",
       "1     1860.000000          0  \n",
       "2     1874.000000          0  \n",
       "3     1872.000000          0  \n",
       "4     1880.000000          0  \n",
       "...           ...        ...  \n",
       "7999  6583.620117   81904200  \n",
       "8000  6622.589844   79574500  \n",
       "8001  6570.189941  214025500  \n",
       "8002  6455.810059  120069400  \n",
       "8003  6552.729980          0  \n",
       "\n",
       "[8004 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 With the selected stock, your first job is to verify the quality  of  the  data.    What are  the  measurements  you  can  apply  to  verify  this quality?\r\n",
    "Why don't we look more closely at the df using pandas built-in methods ?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(cac40df.describe())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Open         High          Low        Close    Adj Close  \\\n",
      "count  8004.000000  8004.000000  8004.000000  8004.000000  8004.000000   \n",
      "mean   3895.171095  3922.428657  3865.036077  3894.662131  3894.662131   \n",
      "std    1348.134244  1355.055374  1340.523331  1347.763769  1347.763769   \n",
      "min    1438.000000  1459.000000  1425.000000  1441.000000  1441.000000   \n",
      "25%    2910.054932  2941.720032  2869.929932  2903.967468  2903.967468   \n",
      "50%    3988.885010  4017.764893  3960.380005  3991.045044  3991.045044   \n",
      "75%    4959.130005  4992.932495  4924.479980  4961.362427  4961.362427   \n",
      "max    6929.049805  6944.770020  6885.640137  6922.330078  6922.330078   \n",
      "\n",
      "             Volume  \n",
      "count  8.004000e+03  \n",
      "mean   6.368138e+07  \n",
      "std    6.962232e+07  \n",
      "min    0.000000e+00  \n",
      "25%    0.000000e+00  \n",
      "50%    6.371910e+07  \n",
      "75%    1.134794e+08  \n",
      "max    5.312476e+08  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trivial security\r\n",
    "Okay, so we can establish as a first trivial criterion that all data must be positive, non-null integers to be clean.\\\r\n",
    "The min value is very interesting as an impossible outlier (<=0) would be immediatly spotted.\\\r\n",
    "In fact, we see that all but the last columns seems to have only positive values (which does not eliminate completely the risk of outliers).\\\r\n",
    "The volumes seem to have cases at 0 - at the first quartile, too. We will have to print the volumes to have a better overview of these 0 values.\\\r\n",
    "We can also assert some integrity values:\r\n",
    "* Outliers according to the std (std +- 3 as seen in class)\r\n",
    "* Values must (or must not ?) take the null value\r\n",
    "\r\n",
    "Let's verify those !\r\n",
    "First the null values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "nullValues = cac40df.isnull().values\r\n",
    "flattenedNullValues = nullValues.ravel()\r\n",
    "filterTrue = flattenedNullValues == True\r\n",
    "flattenedNullValues[filterTrue]\r\n",
    "flattenedNullValues[filterTrue].sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ok se we have no null values all across the board, which is good because there can be multiple ways to solve that before feeding the data to the algorithm. Now let's check for outliers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "colNames = cac40df.columns\r\n",
    "colNames = colNames.drop(\"Date\") #Not verifying that one. We could iterate and verify if we have no \"go-back\", etc.\r\n",
    "\r\n",
    "for colName in colNames:\r\n",
    "    #Calc mean, std\r\n",
    "    col = cac40df[colName]\r\n",
    "    std = col.std()\r\n",
    "    mean = col.mean()\r\n",
    "    # Calc wether we have an outlier\r\n",
    "    outliers = (col > mean + 3*std) | (col < mean - 3*std)\r\n",
    "    areOutliers = outliers[outliers == True]\r\n",
    "    # Compute their number\r\n",
    "    nbr = areOutliers.sum()\r\n",
    "\r\n",
    "    nl = '\\n'\r\n",
    "    print(f\"For col {colName}, std={std}, mean={mean}, {nbr} outliers. values: {nl + str(col[outliers]) if nbr > 0 else 'no'}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For col Open, std=1348.1342440092803, mean=3895.1710951622576, 0 outliers. values: no\n",
      "For col High, std=1355.055373750746, mean=3922.4286571771486, 0 outliers. values: no\n",
      "For col Low, std=1340.523331382823, mean=3865.036077328767, 0 outliers. values: no\n",
      "For col Close, std=1347.7637689858084, mean=3894.6621311689128, 0 outliers. values: no\n",
      "For col Adj Close, std=1347.7637689858084, mean=3894.6621311689128, 0 outliers. values: no\n",
      "For col Volume, std=69622317.31803194, mean=63681383.03348326, 54 outliers. values: \n",
      "4103    286744800\n",
      "4284    285963100\n",
      "4402    295264900\n",
      "4492    286831900\n",
      "4510    365210100\n",
      "4511    463552500\n",
      "4512    353541900\n",
      "4513    323092800\n",
      "4553    290932000\n",
      "4637    278950900\n",
      "4677    305211400\n",
      "4678    316683500\n",
      "4679    284152300\n",
      "4680    300505200\n",
      "4681    531247600\n",
      "4692    277662200\n",
      "4694    372820900\n",
      "4695    272566700\n",
      "4696    466142400\n",
      "4697    301050400\n",
      "4698    315267700\n",
      "4699    278057500\n",
      "4700    341221000\n",
      "4701    298427100\n",
      "4706    324799500\n",
      "4709    303661200\n",
      "5089    284113000\n",
      "5094    274467800\n",
      "5095    331062400\n",
      "5096    438501300\n",
      "5097    413011200\n",
      "5105    279907600\n",
      "5106    291508000\n",
      "5191    278399800\n",
      "5293    274587200\n",
      "5416    285921000\n",
      "5417    373071600\n",
      "5418    324537000\n",
      "5419    409099800\n",
      "5420    396477400\n",
      "5421    403786200\n",
      "5447    360134400\n",
      "5476    282367000\n",
      "5637    286583400\n",
      "5772    274258800\n",
      "6232    304167300\n",
      "6448    323292800\n",
      "6662    415775700\n",
      "7609    329160800\n",
      "7610    280309600\n",
      "7612    371403200\n",
      "7613    326461800\n",
      "7614    311603900\n",
      "7745    279158000\n",
      "Name: Volume, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Okay so the data is pretty clean - no null values and only 54 outliers on the Volume col in the first inspection."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 Can you summarize the values you have? \r\n",
    "I have the values for the cumulated price of the CAC40 index at open, close, and min/max of the day."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 Do the same with the data set Volume.\r\n",
    "?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 Can you measure (and how) the degree of variation that you can find in your data (called volatility in finance).  \r\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "7ed6f5bb5d95a6060489c1e73b807b62943cb606c2473302746af3ad3d902cd5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}